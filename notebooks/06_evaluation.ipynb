{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "222dbc8f-c750-47ef-a7a3-06cc9cef7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.tokens import Span\n",
    "from spacy.training.example import Example\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "TEST_DATA_PATH = Path(\"../data/spaCy/test.spacy\")\n",
    "\n",
    "CRF_MODEL_PATH = Path(\"../models/crf/final_crf_model.joblib\")\n",
    "CNN_MODEL_PATH = Path(\"../models/spaCy/cnn_best/model-best\")\n",
    "TRANSFORMER_MODEL_PATH = Path(\"../models/spaCy/transformer_2/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69faa808-02bd-47a4-bf2e-fd7e40b98350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path):\n",
    "    doc_bin = DocBin().from_disk(path)\n",
    "    return list(doc_bin.get_docs(cnn_model.vocab))\n",
    "\n",
    "test_docs = load_test_data(TEST_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "faea5b9b-8daa-4e24-b83f-ad1a08d6aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CRF model\n",
    "crf_model = joblib.load(CRF_MODEL_PATH)\n",
    "\n",
    "# Load SpaCy CNN model\n",
    "cnn_model = spacy.load(CNN_MODEL_PATH)\n",
    "\n",
    "# Load SpaCy Transformer model\n",
    "transformer_model = spacy.load(TRANSFORMER_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ebfe013-a898-4d0c-abae-9833a8722c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sentence, i):\n",
    "    word = sentence[i][0]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "    }\n",
    "\n",
    "    if i > 0:\n",
    "        prev_word = sentence[i - 1][0]\n",
    "        features.update({\n",
    "            '-1:word.lower()': prev_word.lower(),\n",
    "            '-1:word.istitle()': prev_word.istitle(),\n",
    "            '-1:word.isupper()': prev_word.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sentence) - 1:\n",
    "        next_word = sentence[i + 1][0]\n",
    "        features.update({\n",
    "            '+1:word.lower()': next_word.lower(),\n",
    "            '+1:word.istitle()': next_word.istitle(),\n",
    "            '+1:word.isupper()': next_word.isupper(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "def sentence_to_features(sentence):\n",
    "    return [word2features(sentence, i) for i in range(len(sentence))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dec8752b-05d3-4fc5-bcd1-56968e31237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_predictions(gold_docs, cnn_model, transformer_model, crf_model):\n",
    "    y_true = []\n",
    "    y_pred_cnn = []\n",
    "    y_pred_trans = []\n",
    "    y_pred_crf = []\n",
    "\n",
    "    for doc in gold_docs:\n",
    "        # True entity spans\n",
    "        true_ents = {(ent.start_char, ent.end_char): ent.label_ for ent in doc.ents}\n",
    "\n",
    "        # CNN prediction\n",
    "        pred_cnn = cnn_model(doc.text)\n",
    "        pred_ents_cnn = {(ent.start_char, ent.end_char): ent.label_ for ent in pred_cnn.ents}\n",
    "\n",
    "        # Transformer prediction\n",
    "        pred_trans = transformer_model(doc.text)\n",
    "        pred_ents_trans = {(ent.start_char, ent.end_char): ent.label_ for ent in pred_trans.ents}\n",
    "\n",
    "        # CRF prediction — needs tokenised sentence with dummy tags\n",
    "        tokens = [t.text for t in doc]\n",
    "        dummy_sentence = [(token, \"O\") for token in tokens]\n",
    "        features = sentence_to_features(dummy_sentence)\n",
    "        pred_labels_crf = crf_model.predict_single(features)\n",
    "\n",
    "        # Convert BIO tags to character spans\n",
    "        pred_ents_crf = {}\n",
    "        start = None\n",
    "        current_label = None\n",
    "        for i, tag in enumerate(pred_labels_crf):\n",
    "            if tag.startswith(\"B-\"):\n",
    "                if start is not None:\n",
    "                    end_idx = doc[i - 1].idx + len(doc[i - 1])\n",
    "                    pred_ents_crf[(doc[start].idx, end_idx)] = current_label\n",
    "                start = i\n",
    "                current_label = tag[2:]\n",
    "            elif tag.startswith(\"I-\") and start is not None and tag[2:] == current_label:\n",
    "                continue\n",
    "            else:\n",
    "                if start is not None:\n",
    "                    end_idx = doc[i - 1].idx + len(doc[i - 1])\n",
    "                    pred_ents_crf[(doc[start].idx, end_idx)] = current_label\n",
    "                    start = None\n",
    "                    current_label = None\n",
    "        if start is not None:\n",
    "            end_idx = doc[-1].idx + len(doc[-1])\n",
    "            pred_ents_crf[(doc[start].idx, end_idx)] = current_label\n",
    "\n",
    "        # Align and record predictions\n",
    "        for span, true_label in true_ents.items():\n",
    "            y_true.append(true_label)\n",
    "            y_pred_cnn.append(pred_ents_cnn.get(span, \"O\"))\n",
    "            y_pred_trans.append(pred_ents_trans.get(span, \"O\"))\n",
    "            y_pred_crf.append(pred_ents_crf.get(span, \"O\"))\n",
    "\n",
    "    return y_true, y_pred_cnn, y_pred_trans, y_pred_crf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3f744a-a7a5-4c0a-b12f-ba346e9ee4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_cnn, y_trans, y_crf = flatten_predictions(test_docs, cnn_model, transformer_model, crf_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a593fe8-c558-42be-95cb-50bc302bde03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Weighted Scores\n",
      "            crf   cnn  transformer\n",
      "precision 1.000 0.999        0.998\n",
      "recall    0.983 0.972        0.939\n",
      "f1        0.991 0.985        0.967\n"
     ]
    }
   ],
   "source": [
    "# Extract just the overall (weighted avg) precision, recall, f1 for each model\n",
    "def get_overall_scores(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    return {\n",
    "        \"precision\": round(report[\"weighted avg\"][\"precision\"], 3),\n",
    "        \"recall\": round(report[\"weighted avg\"][\"recall\"], 3),\n",
    "        \"f1\": round(report[\"weighted avg\"][\"f1-score\"], 3),\n",
    "    }\n",
    "\n",
    "overall = pd.DataFrame({\n",
    "    \"crf\": get_overall_scores(y_true, y_crf),\n",
    "    \"cnn\": get_overall_scores(y_true, y_cnn),\n",
    "    \"transformer\": get_overall_scores(y_true, y_trans)\n",
    "})\n",
    "\n",
    "print(\"Overall Weighted Scores\")\n",
    "print(overall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b1b23fa-b08f-42bb-9a94-c17041ea554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-Label Scores\n",
      "             crf_precision  crf_recall  crf_f1  cnn_precision  cnn_recall  \\\n",
      "ENV_PROCESS          1.000       0.981   0.990          1.000       0.980   \n",
      "HABITAT              1.000       0.990   0.995          1.000       0.989   \n",
      "MEASUREMENT          1.000       0.980   0.990          1.000       0.974   \n",
      "POLLUTANT            0.999       0.990   0.994          0.993       0.980   \n",
      "TAXONOMY             0.998       0.973   0.986          0.999       0.932   \n",
      "\n",
      "             cnn_f1  transformer_precision  transformer_recall  transformer_f1  \n",
      "ENV_PROCESS   0.990                  0.999               0.951           0.974  \n",
      "HABITAT       0.995                  0.999               0.979           0.989  \n",
      "MEASUREMENT   0.987                  0.998               0.929           0.962  \n",
      "POLLUTANT     0.986                  0.994               0.946           0.970  \n",
      "TAXONOMY      0.964                  0.997               0.863           0.925  \n"
     ]
    }
   ],
   "source": [
    "# Extract per-label scores only (excluding O, avg rows)\n",
    "def get_per_label_scores(y_true, y_pred, model_name):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    rows = {}\n",
    "    for label in report:\n",
    "        if label in [\"accuracy\", \"macro avg\", \"weighted avg\", \"O\"]:\n",
    "            continue\n",
    "        rows[label] = {\n",
    "            f\"{model_name}_precision\": round(report[label][\"precision\"], 3),\n",
    "            f\"{model_name}_recall\": round(report[label][\"recall\"], 3),\n",
    "            f\"{model_name}_f1\": round(report[label][\"f1-score\"], 3),\n",
    "        }\n",
    "    return pd.DataFrame.from_dict(rows, orient=\"index\")\n",
    "\n",
    "# Create and merge\n",
    "df_crf = get_per_label_scores(y_true, y_crf, \"crf\")\n",
    "df_cnn = get_per_label_scores(y_true, y_cnn, \"cnn\")\n",
    "df_trans = get_per_label_scores(y_true, y_trans, \"transformer\")\n",
    "\n",
    "per_label = pd.concat([df_crf, df_cnn, df_trans], axis=1)\n",
    "\n",
    "print(\"\\nPer-Label Scores\")\n",
    "print(per_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ded37-1864-4591-b89d-0c231e73b209",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc1bf7-e9e4-47f3-8888-41ced89795f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a619241-0400-4e6d-88f0-5221c6344167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2c704-ce9f-4530-8734-79c977d9179d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89772331-6311-4140-b65c-12506dce5e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40405d8c-68cf-4a21-8fcb-80a40c92b326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "229b4445-0e64-4af9-8eea-ed1b8321b78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample input text\n",
    "text = (\n",
    "    \"Fieldwork commenced just after dawn in the upper Wensum catchment, where volunteers recorded temperatures below 6 °C \"\n",
    "    \"and detected elevated levels of nitrates and trace concentrations of microplastics near the riparian buffer zone. \"\n",
    "    \"A cluster of Eurasian badgers was seen retreating into a sett bordering a damp woodland patch, while two red squirrels \"\n",
    "    \"leapt between oak canopies. Near the estuary inlet, European shags were observed preening, with occasional calls echoing \"\n",
    "    \"across the saltmarsh. Later in the morning, we encountered several common chiffchaffs and a grey heron standing motionless \"\n",
    "    \"in the wetland shallows. Evidence of European rabbits digging under bramble thickets was noted alongside tracks left by roe deer. \"\n",
    "    \"Air pressure dropped slightly as cloud cover thickened, consistent with an approaching Atlantic front. Beneath scattered birches, \"\n",
    "    \"we documented a Eurasian coot nest, disturbed only briefly by a curious fox. Scat near a hollow log suggested recent pine marten activity, \"\n",
    "    \"while the adjacent heathland yielded a slow worm and a smooth snake basking in a sunlit patch of leaf litter. \"\n",
    "    \"Near the lower transect, yellowhammers foraged on dried seed heads, and a tawny owl fledgling was spotted perched under a beech branch. \"\n",
    "    \"In a shaded brook, two common frogs swam toward the bank while a solitary common toad remained hidden under moss. \"\n",
    "    \"As the team crossed an open grassland strip, a kestrel hovered overhead and long-tailed tits passed in a burst of movement. \"\n",
    "    \"We documented vocalisations from Eurasian nuthatches and woodpeckers, and spotted a muntjac deer grazing under blackthorn. \"\n",
    "    \"Bank vole tunnels were visible along the hedgerow margin. As dusk approached, the air cooled and pipistrelles emerged, silhouetted \"\n",
    "    \"against the sky. Atmospheric conditions suggested early signs of climate change effects on the breeding rhythms of local amphibians.\"\n",
    ")\n",
    "\n",
    "# Get predictions from CNN and Transformer models\n",
    "results = {}\n",
    "entity_counts = {}\n",
    "\n",
    "doc_cnn = cnn_model(text)\n",
    "doc_transformer = transformer_model(text)\n",
    "\n",
    "results[\"cnn\"] = {(ent.text, ent.label_) for ent in doc_cnn.ents}\n",
    "results[\"transformer\"] = {(ent.text, ent.label_) for ent in doc_transformer.ents}\n",
    "entity_counts[\"cnn\"] = len(results[\"cnn\"])\n",
    "entity_counts[\"transformer\"] = len(results[\"transformer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9bbc761-ca7c-4fb8-b964-52a2cdc0b1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenise the input using SpaCy's English tokenizer\n",
    "nlp_dummy = English()\n",
    "tokens = [token.text for token in nlp_dummy(text)]\n",
    "\n",
    "# Create dummy sentence and extract features\n",
    "sentence = [(t, \"O\") for t in tokens]\n",
    "X_test = sentence_to_features(sentence)\n",
    "y_pred = crf_model.predict_single(X_test)\n",
    "\n",
    "# Convert BIO tags to entity spans\n",
    "spans = []\n",
    "current = []\n",
    "label = None\n",
    "\n",
    "for token, tag in zip(tokens, y_pred):\n",
    "    if tag == 'O':\n",
    "        if current:\n",
    "            spans.append((\" \".join(current), label))\n",
    "            current = []\n",
    "            label = None\n",
    "    elif tag.startswith('B-'):\n",
    "        if current:\n",
    "            spans.append((\" \".join(current), label))\n",
    "        current = [token]\n",
    "        label = tag[2:]\n",
    "    elif tag.startswith('I-') and label == tag[2:]:\n",
    "        current.append(token)\n",
    "    else:\n",
    "        if current:\n",
    "            spans.append((\" \".join(current), label))\n",
    "        current = []\n",
    "        label = None\n",
    "\n",
    "if current:\n",
    "    spans.append((\" \".join(current), label))\n",
    "\n",
    "results[\"crf\"] = set(spans)\n",
    "entity_counts[\"crf\"] = len(spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04b384a1-f222-41a7-990c-3e29126e7178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Entity              | Label       | crf   | cnn   | transformer   |\n",
      "|:--------------------|:------------|:------|:------|:--------------|\n",
      "| ° C                 | MEASUREMENT | ✔     |       |               |\n",
      "| temperatures        | MEASUREMENT | ✔     | ✔     | ✔             |\n",
      "| °C                  | MEASUREMENT |       | ✔     |               |\n",
      "| nitrates            | POLLUTANT   | ✔     | ✔     | ✔             |\n",
      "| microplastics       | POLLUTANT   | ✔     | ✔     |               |\n",
      "| Eurasian badgers    | TAXONOMY    | ✔     | ✔     |               |\n",
      "| badgers             | TAXONOMY    |       |       | ✔             |\n",
      "| red squirrels       | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| estuary             | HABITAT     | ✔     | ✔     | ✔             |\n",
      "| European shags      | TAXONOMY    | ✔     | ✔     |               |\n",
      "| grey heron          | TAXONOMY    | ✔     | ✔     |               |\n",
      "| heron               | TAXONOMY    |       |       | ✔             |\n",
      "| wetland             | HABITAT     | ✔     | ✔     | ✔             |\n",
      "| European rabbits    | TAXONOMY    |       | ✔     |               |\n",
      "| rabbits             | TAXONOMY    | ✔     |       | ✔             |\n",
      "| bramble             | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| roe deer            | TAXONOMY    | ✔     | ✔     |               |\n",
      "| deer                | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| Eurasian coot       | TAXONOMY    | ✔     |       | ✔             |\n",
      "| coot                | TAXONOMY    |       | ✔     |               |\n",
      "| fox                 | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| Scat                | TAXONOMY    | ✔     | ✔     |               |\n",
      "| marten              | TAXONOMY    | ✔     | ✔     |               |\n",
      "| heathland           | HABITAT     | ✔     | ✔     |               |\n",
      "| slow worm           | TAXONOMY    | ✔     |       |               |\n",
      "| smooth snake        | TAXONOMY    |       | ✔     |               |\n",
      "| snake               | TAXONOMY    | ✔     |       | ✔             |\n",
      "| litter              | POLLUTANT   | ✔     | ✔     | ✔             |\n",
      "| yellowhammers       | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| tawny owl           | TAXONOMY    | ✔     | ✔     |               |\n",
      "| owl                 | TAXONOMY    |       |       | ✔             |\n",
      "| brook               | HABITAT     | ✔     | ✔     | ✔             |\n",
      "| common frogs        | TAXONOMY    | ✔     | ✔     |               |\n",
      "| frogs               | TAXONOMY    |       |       | ✔             |\n",
      "| common toad         | TAXONOMY    | ✔     | ✔     |               |\n",
      "| toad                | TAXONOMY    |       |       | ✔             |\n",
      "| grassland           | HABITAT     | ✔     | ✔     | ✔             |\n",
      "| strip               | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| tits                | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| Eurasian nuthatches | TAXONOMY    |       |       | ✔             |\n",
      "| nuthatches          | TAXONOMY    | ✔     | ✔     |               |\n",
      "| woodpeckers         | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| blackthorn          | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| Bank vole           | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| pipistrelles        | TAXONOMY    | ✔     |       | ✔             |\n",
      "| climate change      | ENV_PROCESS | ✔     | ✔     | ✔             |\n",
      "| amphibians          | TAXONOMY    | ✔     | ✔     | ✔             |\n",
      "| **Entity Count**    |             | 37    | 35    | 29            |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Combine all entity predictions\n",
    "all_entities = sorted(set.union(*results.values()), key=lambda x: text.find(x[0]))\n",
    "\n",
    "# Construct table\n",
    "rows = []\n",
    "for span, label in all_entities:\n",
    "    row = {\n",
    "        \"Entity\": span,\n",
    "        \"Label\": label,\n",
    "        \"crf\": \"✔\" if (span, label) in results[\"crf\"] else \"\",\n",
    "        \"cnn\": \"✔\" if (span, label) in results[\"cnn\"] else \"\",\n",
    "        \"transformer\": \"✔\" if (span, label) in results[\"transformer\"] else \"\"\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "# Add count summary row\n",
    "count_row = {\"Entity\": \"**Entity Count**\", \"Label\": \"\"}\n",
    "for name in entity_counts:\n",
    "    count_row[name] = str(entity_counts[name])\n",
    "rows.append(count_row)\n",
    "\n",
    "# Display table\n",
    "df = pd.DataFrame(rows)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "print(df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0466051-10d7-49cd-aec6-e8dc727c2269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER (GPU)",
   "language": "python",
   "name": "ner-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
